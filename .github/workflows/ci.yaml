name: goodnotes_CI

on:
  pull_request:
    branches:
      - main

permissions:
  contents: read
  pull-requests: write
  issues: write
  
jobs:
  build-and-test:
    name: Build and Test with a KinD cluster
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Install Helm
        uses: azure/setup-helm@v4
        with:
          version: 'v3.14.0'

      - name: Create 2-node KinD Cluster
        uses: helm/kind-action@v1.10.0
        with:
          config: kind-config/kind-config.yaml
          cluster_name: ci-cluster

      - name: Deploy NGINX Ingress Controller
        run: |
          # Apply the Ingress controller manifest recommended for KinD
          kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/kind/deploy.yaml

          # Wait for the Ingress controller to be ready before proceeding
          echo "Waiting for Ingress controller to be ready..."
          kubectl wait --namespace ingress-nginx \
            --for=condition=ready pod \
            --selector=app.kubernetes.io/component=controller \
            --timeout=120s

      - name: Verify Cluster and Nodes
        run: |
          echo "Current kubectl context:"
          kubectl cluster-info
          echo -e "\n\nCluster nodes:"
          kubectl get nodes -o wide
          echo -e "\n\nIngress pods:"
          kubectl get pods -n ingress-nginx

      - name: Test Ingress Controller Access
        run: |
          echo "Attempting to curl the Ingress controller via localhost..."
          # We expect a 404 Not Found, which is a success (it doesn't have any Ingress rules configured yet).
          # It proves the NGINX controller is up and responding to HTTP requests.
          # The -f flag makes curl treat HTTP errors (like 404) as a failure,
          # so we invert the exit code with '!' to make the step succeed.
          ! curl -f http://localhost/

      # Task 4: Deploy http-echo applications
      - name: Deploy foo and bar applications
        run: |
          echo "Deploying foo and bar applications..."
          kubectl apply -f k8s/k8s-http-echo-deploy.yaml
          
          echo "Waiting for deployments to be ready..."
          kubectl rollout status deployment/foo-app --timeout=2m
          kubectl rollout status deployment/bar-app --timeout=2m
          
          echo "Applications deployed successfully"

      - name: Verify deployments
        run: |
          echo "=== Foo Deployment ==="
          kubectl get deployment foo-app
          kubectl get pods -l app=foo
          
          echo "=== Bar Deployment ==="
          kubectl get deployment bar-app
          kubectl get pods -l app=bar
          
          echo "=== Services ==="
          kubectl get svc foo-service bar-service

      - name: Create Ingress for http-echo
        run: |
          echo "Creating Ingress resource..."
          kubectl apply -f k8s/k8s-http-echo-ingress.yaml
          
          echo "Waiting for Ingress to be ready..."
          sleep 10
          kubectl get ingress echo-ingress
          kubectl describe ingress echo-ingress

      - name: Test host-based routing with Host headers
        run: |
          echo "Testing foo.localhost with Host header..."
          RESPONSE=$(curl -s -H "Host: foo.localhost" http://localhost/)
          echo "Response: $RESPONSE"
          if [[ "$RESPONSE" == *"foo"* ]]; then
            echo "foo.localhost routing working correctly"
          else
            echo "foo.localhost routing failed"
            echo "Expected: foo"
            echo "Got: $RESPONSE"
            exit 1
          fi
          
          echo ""
          echo "Testing bar.localhost with Host header..."
          RESPONSE=$(curl -s -H "Host: bar.localhost" http://localhost/)
          echo "Response: $RESPONSE"
          if [[ "$RESPONSE" == *"bar"* ]]; then
            echo "bar.localhost routing working correctly"
          else
            echo "bar.localhost routing failed"
            echo "Expected: bar"
            echo "Got: $RESPONSE"
            exit 1
          fi
          
          echo ""
          echo "All host-based routing tests passed!"

      - name: Test invalid hostname (should fail)
        run: |
          echo "Testing invalid hostname (should not route)..."
          RESPONSE=$(curl -s -w "\n%{http_code}" -H "Host: invalid.localhost" http://localhost/)
          HTTP_CODE=$(echo "$RESPONSE" | tail -n1)
          
          if [[ "$HTTP_CODE" == "404" ]]; then
            echo "Invalid hostname correctly rejected with 404"
          else
            echo "Expected 404 for invalid hostname, got: $HTTP_CODE"
          fi
      - name: Deploy Prometheus Stack
        run: |
          echo "Installing Prometheus..."
          
          # Add Prometheus Helm repo
          helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
          helm repo update
          
          # Create monitoring namespace
          kubectl create namespace monitoring
          
          # Install kube-prometheus-stack with minimal resources for CI
          helm install prometheus prometheus-community/kube-prometheus-stack \
            --namespace monitoring \
            --set prometheus.service.type=NodePort \
            --set prometheus.service.nodePort=30090 \
            --set grafana.enabled=false \
            --set alertmanager.enabled=false \
            --set prometheus.prometheusSpec.resources.requests.memory=512Mi \
            --set prometheus.prometheusSpec.resources.limits.memory=1Gi \
            --set prometheus.prometheusSpec.retention=2h \
            --set prometheus.prometheusSpec.scrapeInterval=5s \
            --wait --timeout=5m
          
          echo "Prometheus installed"

      - name: Verify Prometheus is ready
        run: |
          kubectl wait --namespace monitoring \
            --for=condition=ready pod \
            --selector=app.kubernetes.io/name=prometheus \
            --timeout=3m
          
          # Port forward Prometheus to localhost
          kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090 &
          sleep 10
          
          # Test Prometheus API
          curl -s http://localhost:9090/api/v1/query?query=up | jq .
          
          echo "Prometheus is accessible"
      
      - name: Deploy monitoring
        run: |
          kubectl apply -f k8s/servicemonitor.yaml

      - name: Capture baseline metrics
        id: baseline
        run: |
          echo "Capturing baseline metrics..."
          
          # CPU usage baseline
          CPU_BASELINE=$(curl -s 'http://localhost:9090/api/v1/query' \
            --data-urlencode 'query=sum(rate(container_cpu_usage_seconds_total{namespace="default",pod=~".*-app-.*"}[1m]))' \
            | jq -r '.data.result[0].value[1] // "0"')
          
          # Memory usage baseline
          MEM_BASELINE=$(curl -s 'http://localhost:9090/api/v1/query' \
            --data-urlencode 'query=sum(container_memory_working_set_bytes{namespace="default",pod=~".*-app-.*"}) / 1024 / 1024' \
            | jq -r '.data.result[0].value[1] // "0"')
          
          # Network traffic baseline
          NET_RX_BASELINE=$(curl -s 'http://localhost:9090/api/v1/query' \
            --data-urlencode 'query=sum(rate(container_network_receive_bytes_total{namespace="default",pod=~".*-app-.*"}[1m])) / 1024' \
            | jq -r '.data.result[0].value[1] // "0"')
          
          echo "cpu_baseline=$CPU_BASELINE" >> $GITHUB_OUTPUT
          echo "mem_baseline=$MEM_BASELINE" >> $GITHUB_OUTPUT
          echo "net_rx_baseline=$NET_RX_BASELINE" >> $GITHUB_OUTPUT
          
          echo "Baseline - CPU: ${CPU_BASELINE} cores, Memory: ${MEM_BASELINE} MB, Network RX: ${NET_RX_BASELINE} KB/s"

      - name: Debug - Check available metrics
        run: |
          echo "Checking what metrics are available..."
          
          # List all available metrics
          curl -s 'http://localhost:9090/api/v1/label/__name__/values' | jq -r '.data[]' | grep -i container | head -20
          
          # Check if our pods are being scraped
          echo -e "\nChecking for our app pods:"
          curl -s 'http://localhost:9090/api/v1/query' \
            --data-urlencode 'query=up{namespace="default"}' \
            | jq .
          
          # Check CPU metrics specifically
          echo -e "\nChecking CPU metrics:"
          curl -s 'http://localhost:9090/api/v1/query' \
            --data-urlencode 'query=container_cpu_usage_seconds_total{namespace="default"}' \
            | jq '.data.result | length'
          
          # Check memory metrics
          echo -e "\nChecking memory metrics:"
          curl -s 'http://localhost:9090/api/v1/query' \
            --data-urlencode 'query=container_memory_working_set_bytes{namespace="default"}' \
            | jq '.data.result | length'

      - name: Setup k6
        uses: grafana/setup-k6-action@v1

      - name: Run k6 load test
        id: k6_test
        continue-on-error: true
        run: |
          cd k6
          k6 run load-test.js

      - name: Move results to k6 directory
        if: always()
        run: |
          # Results are generated in k6/ directory already since we cd'd there
          ls -la k6/
          
      - name: Parse k6 results
        if: always()
        id: k6_results
        run: |
          SUMMARY_FILE="k6/k6-summary.json"
          
          if [ ! -f "$SUMMARY_FILE" ]; then
            echo "Summary file not found!"
            echo "Contents of k6/:"
            ls -la k6/
            exit 1
          fi
          
          echo "✅ Summary file found"
          
          # Extract metrics using jq
          HTTP_REQS=$(jq -r '.metrics.http_reqs.values.count // 0' $SUMMARY_FILE)
          RPS=$(jq -r '.metrics.http_reqs.values.rate // 0' $SUMMARY_FILE | xargs printf "%.2f")
          DURATION_AVG=$(jq -r '.metrics.http_req_duration.values.avg // 0' $SUMMARY_FILE | xargs printf "%.2f")
          DURATION_P90=$(jq -r '.metrics.http_req_duration.values["p(90)"] // 0' $SUMMARY_FILE | xargs printf "%.2f")
          DURATION_P95=$(jq -r '.metrics.http_req_duration.values["p(95)"] // 0' $SUMMARY_FILE | xargs printf "%.2f")
          DURATION_MAX=$(jq -r '.metrics.http_req_duration.values.max // 0' $SUMMARY_FILE | xargs printf "%.2f")
          FAILED_RATE=$(jq -r '.metrics.http_req_failed.values.rate // 0' $SUMMARY_FILE | awk '{printf "%.2f", $1 * 100}')
          VUS_MAX=$(jq -r '.metrics.vus_max.values.max // 0' $SUMMARY_FILE)
          
          # Export outputs
          echo "http_reqs=$HTTP_REQS" >> $GITHUB_OUTPUT
          echo "rps=$RPS" >> $GITHUB_OUTPUT
          echo "duration_avg=$DURATION_AVG" >> $GITHUB_OUTPUT
          echo "duration_p90=$DURATION_P90" >> $GITHUB_OUTPUT
          echo "duration_p95=$DURATION_P95" >> $GITHUB_OUTPUT
          echo "duration_max=$DURATION_MAX" >> $GITHUB_OUTPUT
          echo "failed_rate=$FAILED_RATE" >> $GITHUB_OUTPUT
          echo "vus_max=$VUS_MAX" >> $GITHUB_OUTPUT
          
          # Check thresholds
          THRESHOLDS_FAILED=$(jq -r '[.metrics | to_entries[] | select(.value.thresholds) | .value.thresholds | to_entries[] | select(.value.ok == false)] | length' $SUMMARY_FILE)
          if [ "$THRESHOLDS_FAILED" -eq 0 ]; then
            echo "thresholds_passed=✅ PASSED" >> $GITHUB_OUTPUT
          else
            echo "thresholds_passed=❌ FAILED ($THRESHOLDS_FAILED threshold(s) failed)" >> $GITHUB_OUTPUT
          fi

      - name: Capture peak metrics during load test
        id: peak_metrics
        if: always()
        run: |
          echo "Waiting for metrics to be collected..."
          sleep 30  # Give Prometheus time to scrape during/after load test
          
          echo "Capturing peak metrics..."
          
          # Use simpler queries with fixed time ranges
          # CPU usage peak (last 3 minutes)
          CPU_PEAK=$(curl -s 'http://localhost:9090/api/v1/query' \
            --data-urlencode 'query=max_over_time(sum(rate(container_cpu_usage_seconds_total{namespace="default",pod=~"foo-app.*|bar-app.*",container!=""}[1m]))[3m:5s])' \
            | jq -r '.data.result[0].value[1] // "0"' | xargs printf "%.4f")
          
          # CPU average during test
          CPU_AVG=$(curl -s 'http://localhost:9090/api/v1/query' \
            --data-urlencode 'query=avg_over_time(sum(rate(container_cpu_usage_seconds_total{namespace="default",pod=~"foo-app.*|bar-app.*",container!=""}[1m]))[3m:5s])' \
            | jq -r '.data.result[0].value[1] // "0"' | xargs printf "%.4f")
          
          # Memory peak (MB) - last 3 minutes
          MEM_PEAK=$(curl -s 'http://localhost:9090/api/v1/query' \
            --data-urlencode 'query=max_over_time(sum(container_memory_working_set_bytes{namespace="default",pod=~"foo-app.*|bar-app.*",container!=""})[3m:5s]) / 1024 / 1024' \
            | jq -r '.data.result[0].value[1] // "0"' | xargs printf "%.2f")
          
          # Memory average (MB)
          MEM_AVG=$(curl -s 'http://localhost:9090/api/v1/query' \
            --data-urlencode 'query=avg_over_time(sum(container_memory_working_set_bytes{namespace="default",pod=~"foo-app.*|bar-app.*",container!=""})[3m:5s]) / 1024 / 1024' \
            | jq -r '.data.result[0].value[1] // "0"' | xargs printf "%.2f")
          
          # Network RX (KB/s)
          NET_RX_PEAK=$(curl -s 'http://localhost:9090/api/v1/query' \
            --data-urlencode 'query=max_over_time(sum(rate(container_network_receive_bytes_total{namespace="default",pod=~"foo-app.*|bar-app.*"}[1m]))[3m:5s]) / 1024' \
            | jq -r '.data.result[0].value[1] // "0"' | xargs printf "%.2f")
          
          # Network TX (KB/s)
          NET_TX_PEAK=$(curl -s 'http://localhost:9090/api/v1/query' \
            --data-urlencode 'query=max_over_time(sum(rate(container_network_transmit_bytes_total{namespace="default",pod=~"foo-app.*|bar-app.*"}[1m]))[3m:5s]) / 1024' \
            | jq -r '.data.result[0].value[1] // "0"' | xargs printf "%.2f")
          
          # Pod restart count
          POD_RESTARTS=$(curl -s 'http://localhost:9090/api/v1/query' \
            --data-urlencode 'query=sum(kube_pod_container_status_restarts_total{namespace="default",pod=~"foo-app.*|bar-app.*"})' \
            | jq -r '.data.result[0].value[1] // "0"')
          
          # Export outputs
          echo "cpu_peak=$CPU_PEAK" >> $GITHUB_OUTPUT
          echo "cpu_avg=$CPU_AVG" >> $GITHUB_OUTPUT
          echo "mem_peak=$MEM_PEAK" >> $GITHUB_OUTPUT
          echo "mem_avg=$MEM_AVG" >> $GITHUB_OUTPUT
          echo "net_rx_peak=$NET_RX_PEAK" >> $GITHUB_OUTPUT
          echo "net_tx_peak=$NET_TX_PEAK" >> $GITHUB_OUTPUT
          echo "pod_restarts=$POD_RESTARTS" >> $GITHUB_OUTPUT
          
          echo "Peak Metrics:"
          echo "  CPU: ${CPU_AVG} cores (avg), ${CPU_PEAK} cores (peak)"
          echo "  Memory: ${MEM_AVG} MB (avg), ${MEM_PEAK} MB (peak)"
          echo "  Network RX: ${NET_RX_PEAK} KB/s (peak)"
          echo "  Network TX: ${NET_TX_PEAK} KB/s (peak)"
          echo "  Pod Restarts: ${POD_RESTARTS}"

      - name: Post enhanced k6 results with resource metrics
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          github-token: ${{ secrets.GITHUB_TOKEN }}
          script: |
            // Parse metrics and add status indicators
            const memPeak = parseFloat('${{ steps.peak_metrics.outputs.mem_peak }}');
            const cpuAvg = parseFloat('${{ steps.peak_metrics.outputs.cpu_avg }}');
            const podRestarts = parseInt('${{ steps.peak_metrics.outputs.pod_restarts }}');
            
            const memStatus = memPeak < 200 ? '✅' : '⚠️';
            const cpuStatus = cpuAvg < 0.5 ? '✅' : '⚠️';
            const restartStatus = podRestarts === 0 ? '✅' : '⚠️';
            const cpuPercent = (cpuAvg * 100).toFixed(1);
            
            const comment = `## 📊 Load Test Results with Resource Monitoring
            
            **Status:** ${{ steps.k6_results.outputs.thresholds_passed }}
            
            ### 🚀 Performance Metrics (k6)
            
            | Metric | Value |
            |--------|-------|
            | **Total Requests** | ${{ steps.k6_results.outputs.http_reqs }} |
            | **Requests/sec** | ${{ steps.k6_results.outputs.rps }} req/s |
            | **Max Virtual Users** | ${{ steps.k6_results.outputs.vus_max }} |
            | **Failed Requests** | ${{ steps.k6_results.outputs.failed_rate }}% |
            
            ### ⏱️ Response Time (HTTP Request Duration)
            
            | Percentile | Time |
            |------------|------|
            | **Average** | ${{ steps.k6_results.outputs.duration_avg }}ms |
            | **P90** | ${{ steps.k6_results.outputs.duration_p90 }}ms |
            | **P95** | ${{ steps.k6_results.outputs.duration_p95 }}ms |
            | **Max** | ${{ steps.k6_results.outputs.duration_max }}ms |
            
            ### 💻 Resource Utilization (Prometheus)
            
            | Resource | Baseline | Average | Peak |
            |----------|----------|---------|------|
            | **CPU** | ${{ steps.baseline.outputs.cpu_baseline }} cores | ${{ steps.peak_metrics.outputs.cpu_avg }} cores | ${{ steps.peak_metrics.outputs.cpu_peak }} cores |
            | **Memory** | ${{ steps.baseline.outputs.mem_baseline }} MB | ${{ steps.peak_metrics.outputs.mem_avg }} MB | ${{ steps.peak_metrics.outputs.mem_peak }} MB |
            | **Network RX** | ${{ steps.baseline.outputs.net_rx_baseline }} KB/s | - | ${{ steps.peak_metrics.outputs.net_rx_peak }} KB/s |
            | **Network TX** | - | - | ${{ steps.peak_metrics.outputs.net_tx_peak }} KB/s |
            
            ### 🔍 Stability Metrics
            
            | Metric | Value | Status |
            |--------|-------|--------|
            | **Pod Restarts** | ${podRestarts} | ${restartStatus} |
            | **Memory Peak** | ${memPeak.toFixed(2)} MB | ${memStatus} |
            | **CPU Utilization** | ${cpuPercent}% avg | ${cpuStatus} |
            
            ### 📋 Test Configuration
            - **Hosts Tested:** \`foo.localhost\`, \`bar.localhost\`
            - **Traffic Pattern:** Randomized across both hosts
            - **Test Duration:** 2 minutes
            - **Load Pattern:** Ramp-up (30s) → Sustained (1m) → Ramp-down (30s)
            - **Monitoring:** Prometheus with 5s scrape interval
            
            ---
            *🤖 Automated by k6 + Prometheus | [View Artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})*
            `;
            
            github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: comment
            });

      - name: Upload k6 results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: k6-load-test-results
          path: |
            k6/k6-summary.json
            k6/k6-results.html
          retention-days: 1

